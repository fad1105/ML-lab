{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1:\n",
    "    Try logistic regression on BuyComputer dataset and set Random state=Your_RollNumber (last 3 digit of ID, incase if you donâ€™t have ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementation of logistic regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased\n",
       "0   19            19000          0\n",
       "1   35            20000          0\n",
       "2   26            43000          0\n",
       "3   27            57000          0\n",
       "4   19            76000          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('BuyComputer.csv')\n",
    "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : \n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1\n",
      " 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1\n",
      " 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0\n",
      " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0\n",
      " 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
      " 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1]\n",
      "\n",
      "x : \n",
      " [[    19  19000]\n",
      " [    35  20000]\n",
      " [    26  43000]\n",
      " [    27  57000]\n",
      " [    19  76000]\n",
      " [    27  58000]\n",
      " [    27  84000]\n",
      " [    32 150000]\n",
      " [    25  33000]\n",
      " [    35  65000]\n",
      " [    26  80000]\n",
      " [    26  52000]\n",
      " [    20  86000]\n",
      " [    32  18000]\n",
      " [    18  82000]\n",
      " [    29  80000]\n",
      " [    47  25000]\n",
      " [    45  26000]\n",
      " [    46  28000]\n",
      " [    48  29000]\n",
      " [    45  22000]\n",
      " [    47  49000]\n",
      " [    48  41000]\n",
      " [    45  22000]\n",
      " [    46  23000]\n",
      " [    47  20000]\n",
      " [    49  28000]\n",
      " [    47  30000]\n",
      " [    29  43000]\n",
      " [    31  18000]\n",
      " [    31  74000]\n",
      " [    27 137000]\n",
      " [    21  16000]\n",
      " [    28  44000]\n",
      " [    27  90000]\n",
      " [    35  27000]\n",
      " [    33  28000]\n",
      " [    30  49000]\n",
      " [    26  72000]\n",
      " [    27  31000]\n",
      " [    27  17000]\n",
      " [    33  51000]\n",
      " [    35 108000]\n",
      " [    30  15000]\n",
      " [    28  84000]\n",
      " [    23  20000]\n",
      " [    25  79000]\n",
      " [    27  54000]\n",
      " [    30 135000]\n",
      " [    31  89000]\n",
      " [    24  32000]\n",
      " [    18  44000]\n",
      " [    29  83000]\n",
      " [    35  23000]\n",
      " [    27  58000]\n",
      " [    24  55000]\n",
      " [    23  48000]\n",
      " [    28  79000]\n",
      " [    22  18000]\n",
      " [    32 117000]\n",
      " [    27  20000]\n",
      " [    25  87000]\n",
      " [    23  66000]\n",
      " [    32 120000]\n",
      " [    59  83000]\n",
      " [    24  58000]\n",
      " [    24  19000]\n",
      " [    23  82000]\n",
      " [    22  63000]\n",
      " [    31  68000]\n",
      " [    25  80000]\n",
      " [    24  27000]\n",
      " [    20  23000]\n",
      " [    33 113000]\n",
      " [    32  18000]\n",
      " [    34 112000]\n",
      " [    18  52000]\n",
      " [    22  27000]\n",
      " [    28  87000]\n",
      " [    26  17000]\n",
      " [    30  80000]\n",
      " [    39  42000]\n",
      " [    20  49000]\n",
      " [    35  88000]\n",
      " [    30  62000]\n",
      " [    31 118000]\n",
      " [    24  55000]\n",
      " [    28  85000]\n",
      " [    26  81000]\n",
      " [    35  50000]\n",
      " [    22  81000]\n",
      " [    30 116000]\n",
      " [    26  15000]\n",
      " [    29  28000]\n",
      " [    29  83000]\n",
      " [    35  44000]\n",
      " [    35  25000]\n",
      " [    28 123000]\n",
      " [    35  73000]\n",
      " [    28  37000]\n",
      " [    27  88000]\n",
      " [    28  59000]\n",
      " [    32  86000]\n",
      " [    33 149000]\n",
      " [    19  21000]\n",
      " [    21  72000]\n",
      " [    26  35000]\n",
      " [    27  89000]\n",
      " [    26  86000]\n",
      " [    38  80000]\n",
      " [    39  71000]\n",
      " [    37  71000]\n",
      " [    38  61000]\n",
      " [    37  55000]\n",
      " [    42  80000]\n",
      " [    40  57000]\n",
      " [    35  75000]\n",
      " [    36  52000]\n",
      " [    40  59000]\n",
      " [    41  59000]\n",
      " [    36  75000]\n",
      " [    37  72000]\n",
      " [    40  75000]\n",
      " [    35  53000]\n",
      " [    41  51000]\n",
      " [    39  61000]\n",
      " [    42  65000]\n",
      " [    26  32000]\n",
      " [    30  17000]\n",
      " [    26  84000]\n",
      " [    31  58000]\n",
      " [    33  31000]\n",
      " [    30  87000]\n",
      " [    21  68000]\n",
      " [    28  55000]\n",
      " [    23  63000]\n",
      " [    20  82000]\n",
      " [    30 107000]\n",
      " [    28  59000]\n",
      " [    19  25000]\n",
      " [    19  85000]\n",
      " [    18  68000]\n",
      " [    35  59000]\n",
      " [    30  89000]\n",
      " [    34  25000]\n",
      " [    24  89000]\n",
      " [    27  96000]\n",
      " [    41  30000]\n",
      " [    29  61000]\n",
      " [    20  74000]\n",
      " [    26  15000]\n",
      " [    41  45000]\n",
      " [    31  76000]\n",
      " [    36  50000]\n",
      " [    40  47000]\n",
      " [    31  15000]\n",
      " [    46  59000]\n",
      " [    29  75000]\n",
      " [    26  30000]\n",
      " [    32 135000]\n",
      " [    32 100000]\n",
      " [    25  90000]\n",
      " [    37  33000]\n",
      " [    35  38000]\n",
      " [    33  69000]\n",
      " [    18  86000]\n",
      " [    22  55000]\n",
      " [    35  71000]\n",
      " [    29 148000]\n",
      " [    29  47000]\n",
      " [    21  88000]\n",
      " [    34 115000]\n",
      " [    26 118000]\n",
      " [    34  43000]\n",
      " [    34  72000]\n",
      " [    23  28000]\n",
      " [    35  47000]\n",
      " [    25  22000]\n",
      " [    24  23000]\n",
      " [    31  34000]\n",
      " [    26  16000]\n",
      " [    31  71000]\n",
      " [    32 117000]\n",
      " [    33  43000]\n",
      " [    33  60000]\n",
      " [    31  66000]\n",
      " [    20  82000]\n",
      " [    33  41000]\n",
      " [    35  72000]\n",
      " [    28  32000]\n",
      " [    24  84000]\n",
      " [    19  26000]\n",
      " [    29  43000]\n",
      " [    19  70000]\n",
      " [    28  89000]\n",
      " [    34  43000]\n",
      " [    30  79000]\n",
      " [    20  36000]\n",
      " [    26  80000]\n",
      " [    35  22000]\n",
      " [    35  39000]\n",
      " [    49  74000]\n",
      " [    39 134000]\n",
      " [    41  71000]\n",
      " [    58 101000]\n",
      " [    47  47000]\n",
      " [    55 130000]\n",
      " [    52 114000]\n",
      " [    40 142000]\n",
      " [    46  22000]\n",
      " [    48  96000]\n",
      " [    52 150000]\n",
      " [    59  42000]\n",
      " [    35  58000]\n",
      " [    47  43000]\n",
      " [    60 108000]\n",
      " [    49  65000]\n",
      " [    40  78000]\n",
      " [    46  96000]\n",
      " [    59 143000]\n",
      " [    41  80000]\n",
      " [    35  91000]\n",
      " [    37 144000]\n",
      " [    60 102000]\n",
      " [    35  60000]\n",
      " [    37  53000]\n",
      " [    36 126000]\n",
      " [    56 133000]\n",
      " [    40  72000]\n",
      " [    42  80000]\n",
      " [    35 147000]\n",
      " [    39  42000]\n",
      " [    40 107000]\n",
      " [    49  86000]\n",
      " [    38 112000]\n",
      " [    46  79000]\n",
      " [    40  57000]\n",
      " [    37  80000]\n",
      " [    46  82000]\n",
      " [    53 143000]\n",
      " [    42 149000]\n",
      " [    38  59000]\n",
      " [    50  88000]\n",
      " [    56 104000]\n",
      " [    41  72000]\n",
      " [    51 146000]\n",
      " [    35  50000]\n",
      " [    57 122000]\n",
      " [    41  52000]\n",
      " [    35  97000]\n",
      " [    44  39000]\n",
      " [    37  52000]\n",
      " [    48 134000]\n",
      " [    37 146000]\n",
      " [    50  44000]\n",
      " [    52  90000]\n",
      " [    41  72000]\n",
      " [    40  57000]\n",
      " [    58  95000]\n",
      " [    45 131000]\n",
      " [    35  77000]\n",
      " [    36 144000]\n",
      " [    55 125000]\n",
      " [    35  72000]\n",
      " [    48  90000]\n",
      " [    42 108000]\n",
      " [    40  75000]\n",
      " [    37  74000]\n",
      " [    47 144000]\n",
      " [    40  61000]\n",
      " [    43 133000]\n",
      " [    59  76000]\n",
      " [    60  42000]\n",
      " [    39 106000]\n",
      " [    57  26000]\n",
      " [    57  74000]\n",
      " [    38  71000]\n",
      " [    49  88000]\n",
      " [    52  38000]\n",
      " [    50  36000]\n",
      " [    59  88000]\n",
      " [    35  61000]\n",
      " [    37  70000]\n",
      " [    52  21000]\n",
      " [    48 141000]\n",
      " [    37  93000]\n",
      " [    37  62000]\n",
      " [    48 138000]\n",
      " [    41  79000]\n",
      " [    37  78000]\n",
      " [    39 134000]\n",
      " [    49  89000]\n",
      " [    55  39000]\n",
      " [    37  77000]\n",
      " [    35  57000]\n",
      " [    36  63000]\n",
      " [    42  73000]\n",
      " [    43 112000]\n",
      " [    45  79000]\n",
      " [    46 117000]\n",
      " [    58  38000]\n",
      " [    48  74000]\n",
      " [    37 137000]\n",
      " [    37  79000]\n",
      " [    40  60000]\n",
      " [    42  54000]\n",
      " [    51 134000]\n",
      " [    47 113000]\n",
      " [    36 125000]\n",
      " [    38  50000]\n",
      " [    42  70000]\n",
      " [    39  96000]\n",
      " [    38  50000]\n",
      " [    49 141000]\n",
      " [    39  79000]\n",
      " [    39  75000]\n",
      " [    54 104000]\n",
      " [    35  55000]\n",
      " [    45  32000]\n",
      " [    36  60000]\n",
      " [    52 138000]\n",
      " [    53  82000]\n",
      " [    41  52000]\n",
      " [    48  30000]\n",
      " [    48 131000]\n",
      " [    41  60000]\n",
      " [    41  72000]\n",
      " [    42  75000]\n",
      " [    36 118000]\n",
      " [    47 107000]\n",
      " [    38  51000]\n",
      " [    48 119000]\n",
      " [    42  65000]\n",
      " [    40  65000]\n",
      " [    57  60000]\n",
      " [    36  54000]\n",
      " [    58 144000]\n",
      " [    35  79000]\n",
      " [    38  55000]\n",
      " [    39 122000]\n",
      " [    53 104000]\n",
      " [    35  75000]\n",
      " [    38  65000]\n",
      " [    47  51000]\n",
      " [    47 105000]\n",
      " [    41  63000]\n",
      " [    53  72000]\n",
      " [    54 108000]\n",
      " [    39  77000]\n",
      " [    38  61000]\n",
      " [    38 113000]\n",
      " [    37  75000]\n",
      " [    42  90000]\n",
      " [    37  57000]\n",
      " [    36  99000]\n",
      " [    60  34000]\n",
      " [    54  70000]\n",
      " [    41  72000]\n",
      " [    40  71000]\n",
      " [    42  54000]\n",
      " [    43 129000]\n",
      " [    53  34000]\n",
      " [    47  50000]\n",
      " [    42  79000]\n",
      " [    42 104000]\n",
      " [    59  29000]\n",
      " [    58  47000]\n",
      " [    46  88000]\n",
      " [    38  71000]\n",
      " [    54  26000]\n",
      " [    60  46000]\n",
      " [    60  83000]\n",
      " [    39  73000]\n",
      " [    59 130000]\n",
      " [    37  80000]\n",
      " [    46  32000]\n",
      " [    46  74000]\n",
      " [    42  53000]\n",
      " [    41  87000]\n",
      " [    58  23000]\n",
      " [    42  64000]\n",
      " [    48  33000]\n",
      " [    44 139000]\n",
      " [    49  28000]\n",
      " [    57  33000]\n",
      " [    56  60000]\n",
      " [    49  39000]\n",
      " [    39  71000]\n",
      " [    47  34000]\n",
      " [    48  35000]\n",
      " [    48  33000]\n",
      " [    47  23000]\n",
      " [    45  45000]\n",
      " [    60  42000]\n",
      " [    39  59000]\n",
      " [    46  41000]\n",
      " [    51  23000]\n",
      " [    50  20000]\n",
      " [    36  33000]\n",
      " [    49  36000]]\n"
     ]
    }
   ],
   "source": [
    "label=data.iloc[:,-1].values\n",
    "x=data.iloc[:,:-1].values\n",
    "\n",
    "print('label : \\n',label)\n",
    "print('\\nx : \\n',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "240\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,label,test_size=0.4,random_state=61)\n",
    "\n",
    "sc=StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "y_pred  = []\n",
    "len_x=len(x_train[0])\n",
    "w = []\n",
    "b=0.2\n",
    "print(len_x)\n",
    "\n",
    "entries = len(x_train[:,0])\n",
    "print(entries)\n",
    "for weights in range(len_x):\n",
    "    w.append(0)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    final = 1/(1+np.exp(-z))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(y,a):\n",
    "    aT=a.T\n",
    "    j= (-1/entries) * (np.sum((aT*np.log(y)) + ((1-aT) * (np.log(1-y)))))\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs,m):\n",
    "    print(m)\n",
    "    y_pred=np.zeros(m);\n",
    "    for i in range(m):\n",
    "        if inputs[i] > 0.5:\n",
    "            y_pred[i] = 1\n",
    "    return y_pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = []\n",
    "db = 0\n",
    "J = 0\n",
    "alpha = 0.1\n",
    "for x in range(len_x):\n",
    "    dw.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weight :  [2.35625942 1.04217951]\n",
      "\n",
      "Bias :  -0.9112948033494777\n",
      "240\n",
      "pridiction of x_train: \n",
      " [1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "160\n",
      "pridiction of x_test: \n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3000):\n",
    "    y=sigmoid((np.dot(w,x_train.T)+b));\n",
    "    cost = loss_func(y,y_train);\n",
    "    dw = (1/entries) * (np.dot(x_train.T,(y-y_train.T).T));\n",
    "    db=(1/entries) * (np.sum(y-y_train.T))\n",
    "    w=w-(alpha * dw.T)\n",
    "    b=b-(alpha * db)\n",
    "\n",
    "print(\"\\nWeight : \",w)\n",
    "print(\"\\nBias : \" ,b)\n",
    "\n",
    "train_pred=sigmoid(np.dot(w,x_train.T)+b)\n",
    "\n",
    "test_pred=sigmoid(np.dot(w,x_test.T)+b)\n",
    "\n",
    "y_pred=predict(train_pred,x_train.shape[0])\n",
    "print('pridiction of x_train: \\n',y_pred)\n",
    "\n",
    "x_pred_test=predict(test_pred,x_test.shape[0])\n",
    "print('pridiction of x_test: \\n',x_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actal value\n",
      " [0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0\n",
      " 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 1 0 1 0 0 0 1 0 0] (160,)\n",
      "\n",
      "accuracy score :  0.86875\n"
     ]
    }
   ],
   "source": [
    "print(\"actal value\\n\" ,y_test,y_test.shape)\n",
    "\n",
    "print(\"\\naccuracy score : \",accuracy_score(x_pred_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Defualt Logistic Regressionation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy score :  0.86875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrmodel= LogisticRegression(random_state = 61)\n",
    "\n",
    "lrmodel.fit(x_train,y_train)\n",
    "\n",
    "pred=lrmodel.predict(x_test)\n",
    "\n",
    "print(\"\\naccuracy score : \",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "    tenserflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#step 2\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "\n",
    "\n",
    "num_features=784\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
    "print(x_train.shape)\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "num_classes = 10 # 0 to 9 digits\n",
    "num_features = 784 # 28*28\n",
    "learning_rate = 0.01\n",
    "training_steps = 1000\n",
    "batch_size = 256\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>\n"
     ]
    }
   ],
   "source": [
    "#step 4\n",
    "train_data=tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'weight:0' shape=(784, 10) dtype=float32, numpy=\n",
      "array([[1., 1., 1., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.],\n",
      "       ...,\n",
      "       [1., 1., 1., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>\n",
      "<tf.Variable 'bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#step 5\n",
    "W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\n",
    "print(W)\n",
    "b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 6\n",
    "def logistic_regression(x):\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 7\n",
    "def accuracy(y_pred, y_true):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 8\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "def run_optimization(x, y):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = logistic_regression(x)\n",
    "        loss = cross_entropy(pred, y)\n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50, loss: 101.692055, accuracy: 0.875000\n",
      "step: 100, loss: 404.427185, accuracy: 0.804688\n",
      "step: 150, loss: 85.828964, accuracy: 0.882812\n",
      "step: 200, loss: 149.444397, accuracy: 0.839844\n",
      "step: 250, loss: 69.942780, accuracy: 0.949219\n",
      "step: 300, loss: 54.240543, accuracy: 0.925781\n",
      "step: 350, loss: 85.036575, accuracy: 0.917969\n",
      "step: 400, loss: 79.239136, accuracy: 0.906250\n",
      "step: 450, loss: 92.954590, accuracy: 0.914062\n",
      "step: 500, loss: 49.279919, accuracy: 0.933594\n",
      "step: 550, loss: 65.475288, accuracy: 0.921875\n",
      "step: 600, loss: 213.495209, accuracy: 0.816406\n",
      "step: 650, loss: 196.741058, accuracy: 0.820312\n",
      "step: 700, loss: 56.278732, accuracy: 0.945312\n",
      "step: 750, loss: 62.125683, accuracy: 0.949219\n",
      "step: 800, loss: 68.059639, accuracy: 0.921875\n",
      "step: 850, loss: 34.486893, accuracy: 0.953125\n",
      "step: 900, loss: 56.857357, accuracy: 0.945312\n",
      "step: 950, loss: 68.902626, accuracy: 0.937500\n",
      "step: 1000, loss: 103.854294, accuracy: 0.902344\n"
     ]
    }
   ],
   "source": [
    "#step 9\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    if step % display_step == 0:\n",
    "        prediction = logistic_regression(batch_x)\n",
    "        loss = cross_entropy(prediction, batch_y)\n",
    "        accurracy = accuracy(prediction, batch_y)\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, accurracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.904100\n"
     ]
    }
   ],
   "source": [
    "#step 10\n",
    "prediction = logistic_regression(x_test)\n",
    "\n",
    "print(\"Test Accuracy: %f\" % accuracy(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
